{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c385112-a503-4ae4-a3a3-75d367f558ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81c93baf-e466-4ef9-a198-a0523e58b0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOKBACK = 63 # на сколько трейдинговых дней смотрим назад (для определения средней волатильности)\n",
    "DOLLAR_VOL_THRESHOLD = 5_000_000 # порог с которого перестаем считать компанию микро стоком\n",
    "WINDOW_SIZE = 30 # то, какое окно используем в лстм для предсказания следующего значения\n",
    "HIDDEN_SIZE = 64\n",
    "\n",
    "def prepare_dataset(df, company):\n",
    "    global LOOKBACK, DOLLAR_VOL_THRESHOLD\n",
    "    \n",
    "    ds = pd.DataFrame()\n",
    "    recent_data = df.tail(LOOKBACK)\n",
    "    avg_dollar_vol = (recent_data['Adj Close'] * recent_data['Volume']).mean()\n",
    "    if avg_dollar_vol < DOLLAR_VOL_THRESHOLD: #micro stock\n",
    "        print(f'{company} is considered a micro stock: {avg_dollar_vol}$', end='\\r')\n",
    "        return ds\n",
    "\n",
    "    df['Date'] = pd.to_datetime(df['Date'], yearfirst=True)\n",
    "    ds['date'] = df['Date']\n",
    "    ds['price'] = df['Close']\n",
    "    \n",
    "    ds['rolling_mean'] = df['Close'].rolling(window=7).sum()/7/df['Close']\n",
    "    rolling_sum_sq = (df['Close']**2).rolling(window=7).sum()\n",
    "    term = rolling_sum_sq / (7 * df['Close']**2)\n",
    "    variance = term - ds['rolling_mean']**2\n",
    "    variance_clipped = variance.clip(lower=0)\n",
    "    ds['rolling_std'] = np.sqrt(variance_clipped)\n",
    "\n",
    "    ds['weekday'] = df['Date'].dt.dayofweek\n",
    "    ds['month'] = df['Date'].dt.month\n",
    "    ds['quarter'] = df['Date'].dt.quarter\n",
    "\n",
    "    ds['long_skewness'] = df['Close'].rolling(window=30).skew()\n",
    "    ds['short_skewness'] = df['Close'].rolling(window=7).skew()\n",
    "    \n",
    "    ds['long_kurtosis'] = df['Close'].rolling(window=30).kurt()\n",
    "    ds['short_kurtosis'] = df['Close'].rolling(window=7).kurt()\n",
    "\n",
    "    for day in (1, 2, 7):\n",
    "        ds[f'lag_{day}'] = df['Close'].shift(day)/df['Close']\n",
    "\n",
    "    ds['change'] = df['Close'].pct_change(fill_method=None).shift(-1)\n",
    "\n",
    "    ds = ds.replace([np.inf, -np.inf], np.nan)\n",
    "    ds = ds.dropna()\n",
    "    ds = ds[~(ds.drop(columns=['weekday']) == 0).any(axis=1)]\n",
    "\n",
    "    ds['grew'] = ds['change'].apply(lambda x: 0 if x < 0 else 1) # таргет - следующий день, поэтому выше никаких ликов не случилось\n",
    "    \n",
    "    ds = ds.reset_index(drop=True)\n",
    "    return ds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2b4d6bd-5683-4120-96e8-86c082e9d509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTW is considered a micro stock: 635161.0294039288$9$$"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class TrendDataset(Dataset):\n",
    "    def __init__(self, chunks):\n",
    "        self.inputs = torch.tensor(\n",
    "            np.array([chunk.drop(columns=[\"grew\", \"change\"]).values for chunk in chunks]),\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "        \n",
    "        self.target = torch.tensor(\n",
    "            [chunk[\"grew\"].iloc[-1] for chunk in chunks],\n",
    "            dtype=torch.float32\n",
    "        ).unsqueeze(-1)\n",
    "\n",
    "        self.returns = torch.tensor(\n",
    "            [chunk[\"change\"].iloc[-1] for chunk in chunks],\n",
    "            dtype=torch.float32\n",
    "        ).unsqueeze(-1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.inputs[idx], self.target[idx], self.returns[idx])\n",
    "\n",
    "files_dir = 'dataset/stocks'\n",
    "files = os.listdir(files_dir)\n",
    "random.Random(97).shuffle(files) # сид для воспроизводимости\n",
    "\n",
    "trader_agent_dir = 'trader-agent'\n",
    "train_files, test_files = train_test_split(files, test_size=0.1)\n",
    "\n",
    "train_dataloaders = [] # т.к. батчи не должны пересекаться между компаниями\n",
    "test_dataloaders = []\n",
    "\n",
    "if not os.path.exists(trader_agent_dir):\n",
    "    for split in ['train', 'test']:\n",
    "        os.makedirs(os.path.join(trader_agent_dir, split))\n",
    "\n",
    "def process_company_ds(ds, batch_size=64):\n",
    "    global WINDOW_SIZE\n",
    "    chunks = [ds[i:i + WINDOW_SIZE].copy() for i in range(0, len(ds)-WINDOW_SIZE)]\n",
    "    if len(chunks[-1]) != WINDOW_SIZE:\n",
    "        chunks = chunks[:-1]\n",
    "    return DataLoader(TrendDataset(chunks), batch_size=batch_size)\n",
    "    \n",
    "for file in files:\n",
    "    df = pd.read_csv(os.path.join(files_dir, file))\n",
    "    company = file[:file.find('.csv')]\n",
    "    company_df = prepare_dataset(df, company)\n",
    "\n",
    "    if len(company_df)<WINDOW_SIZE: \n",
    "        continue\n",
    "    elif file in train_files:\n",
    "        company_df.drop(columns=[\"change\", \"grew\"]).to_csv(os.path.join(trader_agent_dir, 'train', file), index=False)\n",
    "        company_df = company_df.drop(columns=[\"date\", \"price\"])\n",
    "        train_dataloaders.append(process_company_ds(company_df))\n",
    "        \n",
    "    elif file in test_files:\n",
    "        company_df.drop(columns=[\"change\", \"grew\"]).to_csv(os.path.join(trader_agent_dir, 'test', file), index=False)\n",
    "        company_df = company_df.drop(columns=[\"date\", \"price\"])\n",
    "        test_dataloaders.append(process_company_ds(company_df, len(company_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d98ea3c1-f59b-46e1-a6f2-3d25b16faa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "class TrendPredictor(nn.Module):\n",
    "    def __init__(self, num_features, hidden_size=HIDDEN_SIZE):\n",
    "        super(TrendPredictor, self).__init__()\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.do = nn.Dropout(0.1)\n",
    "        self.LSTM = nn.LSTM(num_features, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.LSTM(x)  # out: (batch, seq_len, hidden_size)\n",
    "        out = self.do(out)\n",
    "        return nn.functional.sigmoid(self.fc(out[:, -1, :]))  # только последний таймстеп интересует\n",
    "\n",
    "model = TrendPredictor(num_features=12)\n",
    "loss_fn = nn.BCELoss()\n",
    "lr = 1e-4\n",
    "optim = torch.optim.AdamW(model.parameters(), lr = lr, weight_decay = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40738272-2a02-42fc-9ea4-c8067eb7db8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train BCE: 0.6926, Test F1: 0.6192\n",
      "Train BCE: 0.6914, Test F1: 0.6053\n",
      "Train BCE: 0.6902, Test F1: 0.5940\n",
      "Train BCE: 0.6884, Test F1: 0.5906\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "num_epochs = 100\n",
    "patience = 3\n",
    "best_score = 0\n",
    "bad_epochs = 0\n",
    "torch.set_num_threads(14) # cpu goes brrr\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_running_loss = 0.0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for train_dl in train_dataloaders:\n",
    "        for batch in train_dl:\n",
    "            inputs, targets, returns = batch\n",
    "            optim.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            \n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "            train_running_loss += loss.item() * inputs.size(0)\n",
    "            total_samples += inputs.size(0)\n",
    "    \n",
    "    model.eval()\n",
    "    all_targets = []\n",
    "    all_preds = []\n",
    "    \n",
    "    for test_dl in test_dataloaders:\n",
    "        for batch in test_dl:\n",
    "            inputs, targets, returns = batch\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "                preds = torch.round(outputs)\n",
    "            \n",
    "            all_targets.append(targets)\n",
    "            all_preds.append(preds)\n",
    "    \n",
    "    global_targets = torch.cat(all_targets)\n",
    "    global_preds = torch.cat(all_preds)\n",
    "    f1 = f1_score(global_targets, global_preds, pos_label=1)\n",
    "\n",
    "    avg_loss = train_running_loss / total_samples\n",
    "    \n",
    "    print(f\"Train BCE: {avg_loss:.4f}, Test F1: {f1:.4f}\")\n",
    "    \n",
    "    if f1 > best_score:\n",
    "        torch.save(model.state_dict(), 'lstm_predictor_best.pt')\n",
    "        best_score = f1\n",
    "        bad_epochs = 0\n",
    "    else:\n",
    "        bad_epochs += 1\n",
    "        if bad_epochs >= patience:\n",
    "            print(\"Early stopping\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "769f8ab8-5bcb-4ee9-8b33-5d972bb10525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrendPredictor(\n",
       "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (do): Dropout(p=0.1, inplace=False)\n",
       "  (LSTM): LSTM(12, 64, batch_first=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TrendPredictor(num_features=12)\n",
    "model.load_state_dict(torch.load('new_predictor_best.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d5d5f2b-6667-4c5d-b48a-2da9d8d04d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Ratio: 0.508\n",
      "Sharpe Ratio: 0.537\n",
      "Sharpe Ratio: 0.370\n",
      "Sharpe Ratio: 0.335\n",
      "Sharpe Ratio: 0.106\n",
      "Sharpe Ratio: 0.638\n",
      "Sharpe Ratio: 0.632\n",
      "Sharpe Ratio: 0.208\n",
      "Sharpe Ratio: 0.506\n",
      "Sharpe Ratio: 0.437\n",
      "Sharpe Ratio: 0.541\n",
      "Sharpe Ratio: 0.058\n",
      "Sharpe Ratio: -0.120\n",
      "Sharpe Ratio: 0.330\n",
      "Sharpe Ratio: 1.476\n",
      "Sharpe Ratio: 0.807\n",
      "Sharpe Ratio: 0.151\n",
      "Sharpe Ratio: 0.880\n",
      "Sharpe Ratio: -0.019\n",
      "Sharpe Ratio: -0.946\n",
      "Sharpe Ratio: 0.385\n",
      "Sharpe Ratio: 0.118\n",
      "Sharpe Ratio: 0.716\n",
      "Sharpe Ratio: 0.512\n",
      "Sharpe Ratio: 0.891\n",
      "Sharpe Ratio: 0.332\n",
      "Sharpe Ratio: -0.001\n",
      "Sharpe Ratio: 0.717\n",
      "Sharpe Ratio: -0.551\n",
      "Sharpe Ratio: -1.108\n",
      "Sharpe Ratio: 0.200\n",
      "Sharpe Ratio: 0.528\n",
      "Sharpe Ratio: 0.744\n",
      "Sharpe Ratio: 0.680\n",
      "Sharpe Ratio: 0.730\n",
      "Sharpe Ratio: 1.066\n",
      "Sharpe Ratio: 0.509\n",
      "Sharpe Ratio: 0.526\n",
      "Sharpe Ratio: 0.278\n",
      "Sharpe Ratio: -1.256\n",
      "Sharpe Ratio: 0.742\n",
      "Sharpe Ratio: 0.395\n",
      "Sharpe Ratio: 0.629\n",
      "Sharpe Ratio: 0.398\n",
      "Sharpe Ratio: 0.582\n",
      "Sharpe Ratio: 0.123\n",
      "Sharpe Ratio: 0.546\n",
      "Sharpe Ratio: 0.341\n",
      "Sharpe Ratio: 0.095\n",
      "Sharpe Ratio: 1.192\n",
      "\n",
      "Average Sharpe Ratio: 0.370\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sharpe_values = []\n",
    "instances_count = 0\n",
    "\n",
    "for test_dl in test_dataloaders[:50]:\n",
    "    instances_count += 1\n",
    "    for batch in test_dl:\n",
    "        inputs, targets, returns = batch\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.round(outputs)\n",
    "\n",
    "        profits = []\n",
    "        for preds, rets in zip(preds, returns):\n",
    "            profit = preds * rets  # если не покупали — 0, если покупали — доходность\n",
    "            profits.append(profit)\n",
    "        \n",
    "        profits = torch.cat(profits).numpy()\n",
    "        cum_profit = np.cumsum(profits)\n",
    "\n",
    "        # Sharpe Ratio\n",
    "        mean_return = np.mean(profits)\n",
    "        std_return = np.std(profits)\n",
    "        sharpe = (mean_return / std_return) * np.sqrt(252) if std_return != 0 else 0.0\n",
    "        sharpe_values.append(sharpe)\n",
    "        print(f\"Sharpe Ratio: {sharpe:.3f}\")\n",
    "\n",
    "        # Plot Cumulative Profit\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(np.arange(len(cum_profit)), cum_profit)\n",
    "        plt.xlabel(\"Day\")\n",
    "        plt.ylabel(\"Cumulative Profit\")\n",
    "        plt.title(f\"Cumulative Profit Curve — Sharpe: {sharpe:.3f}\")\n",
    "        plt.savefig(f'predictor_eval/{instances_count}.png', bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "# Print average Sharpe ratio\n",
    "if sharpe_values:\n",
    "    avg_sharpe = sum(sharpe_values) / len(sharpe_values)\n",
    "    print(f\"\\nAverage Sharpe Ratio: {avg_sharpe:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9ddaa1-0d45-4b74-a789-78b86e0354cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_env",
   "language": "python",
   "name": "project_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
